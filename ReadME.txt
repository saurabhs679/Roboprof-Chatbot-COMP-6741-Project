Queries-Contains Sparql queries in notepad format(Total 13)
Queries Output-COntain output in csv format(Total 13)


CSV files-The following csv files are used to run code.Upload them on jupyter

Intelligent_Systems.csv  -  Contains Course information
Lectures_information.csv   -  Contains Lectures information for courses
Student_information.csv  -  Contains Students information  for courses
Topic_information.csv - Contains Topics information for courses
Univ.csv - Contain University Details
CATALOG.csv - Opendataset containing courses information

IPYNB  files_ upload these on jupyter to run them

N-Triple.ipynb - To convert Turtle file to N-triples.
SPARQL queries.ipynb - Run SparQl queries in python and convert into merged_data.ttl file 
Course_Catalog.ipynb - Create Knowledge base of open dataset CSV
Knowledge graph automated.ipynb - We are using this to populate all our vocabulary using all the csv files
Knowledge Graph Vocabulary.ipynb - We used this to create our Vocabulary

merged_data.nt - N-Triples for the Constructed Knowledge base
Course_Catalog.ttl - Turtle file for Course Information
merged_data.ttl - This turtle contain our complete Knowledge base
Vocabulary.ttl - Basic Vocabulary in turtle format

Expectations-of-Originality-Anubhav Mahajan.pdf - Expectation of Originality form
Expectations-of-Originality-Saurabh - Expectation of Originality form

Project Report - report on design and implementation

To run the code upload ipynb, .ttl, .nt and csv files into jupyter Notebook and run each cell. 
To run queries we need Apache Fuseki . Upload the merged_data.ttl into Fuseki and take queries from queries folder and run them

